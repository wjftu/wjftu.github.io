"use strict";(self.webpackChunkwjftu_ds=self.webpackChunkwjftu_ds||[]).push([[6037],{2666:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>i,contentTitle:()=>d,default:()=>l,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"tool/hadoop","title":"Hadoop","description":"\u5b89\u88c5 ubuntu 20.04 \u865a\u62df\u673a","source":"@site/note/tool/hadoop.md","sourceDirName":"tool","slug":"/tool/hadoop","permalink":"/note/tool/hadoop","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":50,"frontMatter":{"title":"Hadoop","sidebar_position":50},"sidebar":"tutorialSidebar","previous":{"title":"Mongo DB","permalink":"/note/tool/mongo"},"next":{"title":"\u7b14\u8bb0","permalink":"/note/"}}');var a=r(4848),t=r(8453);const s={title:"Hadoop",sidebar_position:50},d="Hadoop",i={},c=[{value:"\u5b89\u88c5 jdk8",id:"\u5b89\u88c5-jdk8",level:3},{value:"\u5b89\u88c5 hadoop",id:"\u5b89\u88c5-hadoop",level:3},{value:"\u914d\u7f6e",id:"\u914d\u7f6e",level:3},{value:"HDFS",id:"hdfs",level:3},{value:"MapReduce \u548c Yarn",id:"mapreduce-\u548c-yarn",level:3},{value:"Hive",id:"hive",level:3}];function p(e){const n={a:"a",br:"br",code:"code",h1:"h1",h3:"h3",header:"header",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"hadoop",children:"Hadoop"})}),"\n",(0,a.jsx)(n.p,{children:"\u5b89\u88c5 ubuntu 20.04 \u865a\u62df\u673a"}),"\n",(0,a.jsx)(n.p,{children:"\u4e5f\u53ef\u4ee5\u662f\u5b9e\u4f53\u673a\uff0c\u4e0d\u8fc7\u6ca1\u90a3\u4e48\u591a\u673a\u5668\u3002\u3002\u3002\u53ef\u4ee5\u7528 virtual box \u5b89\u88c5\u591a\u53f0\u865a\u62df\u673a"}),"\n",(0,a.jsx)(n.p,{children:"\u67e5\u770b\u548c\u540e\u53f0\u542f\u52a8\u865a\u62df\u673a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'VBoxManage list vms\nVBoxManage startvm "uuid" \u2013type headless\n'})}),"\n",(0,a.jsx)(n.p,{children:"\u5b89\u88c5 ifconfig \uff0c\u7528\u4e8e\u67e5\u770bip"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"sudo apt update\nsudo apt upgrade\nsudo apt install ifconfig\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5b89\u88c5 openssh-server \u4ee5\u4fbf\u4e8e ssh \u8fde\u63a5"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"sudo apt install openssh-server\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5b89\u88c5 openssh-server \u9047\u5230\u62a5\u9519\uff0c\u5148\u5b89\u88c5\u4f9d\u8d56"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"sudo apt install openssh-client=1:8.2p1-4ubuntu0.2\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528\u547d\u4ee4 ",(0,a.jsx)(n.code,{children:"ssh-keygen -t rsa"})," \u751f\u6210\u516c\u79c1\u94a5\uff0c\u5c06\u516c\u94a5\u5199\u5165\u670d\u52a1\u5668\u7684 ",(0,a.jsx)(n.code,{children:"~/.ssh/authorized_keys"}),"  \u6587\u4ef6\u5185\uff0c\u4ee5\u4fbf\u514d\u5bc6\u767b\u9646"]}),"\n",(0,a.jsx)(n.p,{children:"debian \u5b89\u88c5"}),"\n",(0,a.jsxs)(n.p,{children:["\u914d\u7f6e\u56fd\u5185\u6e90\uff0c\u53c2\u8003 ",(0,a.jsx)(n.a,{href:"https://developer.aliyun.com/mirror/debian/",children:"https://developer.aliyun.com/mirror/debian/"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"apt update\n# \u5b89\u88c5 ifconfig\napt install net-tools\napt install openssh-server\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u751f\u6210\u5bc6\u94a5"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"ssh-keygen -t rsa\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5c06\u516c\u94a5\u5199\u5165 ~/.ssh/authorizedkeys \uff0c\u4ee5\u4fbf\u514d\u5bc6\u767b\u5f55"}),"\n",(0,a.jsx)(n.h3,{id:"\u5b89\u88c5-jdk8",children:"\u5b89\u88c5 jdk8"}),"\n",(0,a.jsx)(n.p,{children:"\u5c06 jdk-8u202-linux-x64.tar.gz \u6587\u4ef6\u89e3\u538b\u5230 /usr/java"}),"\n",(0,a.jsxs)(n.p,{children:["\u6839\u636e ",(0,a.jsx)(n.a,{href:"https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions",children:"https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions"})," \uff0chadoop 3.2 \u652f\u6301 jdk 8 \u7f16\u8bd1\u548c\u8fd0\u884c"]}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e\u73af\u5883\u53d8\u91cf"}),"\n",(0,a.jsx)(n.p,{children:"\u7f16\u8f91 /etc/profile \uff0c\u6dfb\u52a0"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"export JAVA_HOME=/usr/java/jdk1.8.0_202\nexport PATH=$PATH:$JAVA_HOME/bin\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u8fd0\u884c ",(0,a.jsx)(n.code,{children:"source /etc/profile"})]}),"\n",(0,a.jsx)(n.h3,{id:"\u5b89\u88c5-hadoop",children:"\u5b89\u88c5 hadoop"}),"\n",(0,a.jsx)(n.p,{children:"\u4e0b\u8f7d hadoop \uff0c\u89e3\u538b\u5230\u4e00\u4e2a\u6587\u4ef6\u5939\uff0c\u5982 /server"}),"\n",(0,a.jsx)(n.p,{children:"\u8fd0\u884c bin/hadoop"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# ./bin/hadoop\nUsage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\nor    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\nwhere CLASSNAME is a user-provided Java class\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u9ed8\u8ba4\u662f\u5355\u673a\u6a21\u5f0f\uff0c\u6d4b\u8bd5\u8fd0\u884c"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ mkdir input\n$ cp etc/hadoop/*.xml input\n$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.5.jar grep input output 'dfs[a-z.]+'\n$ cat output/*\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u5355\u8282\u70b9\u548c\u4f2a\u5206\u5e03\u5f0f\u53c2\u8003 ",(0,a.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html",children:"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html"})," \uff0c\u96c6\u7fa4\u53c2\u8003 ttps://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html"]}),"\n",(0,a.jsx)(n.p,{children:"\u7f16\u8f91 etc/hadoop/hadoop-env.sh \uff0c\u6dfb\u52a0"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"export JAVA_HOME=/usr/java/jdk1.8.0_202\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5982\u679c\u662f root \u7528\u6237\uff0c\u8fd8\u9700\u8981\u52a0\u4e0a\u4e0b\u9762\u8fd9\u4e9b\uff0c\u4e0d\u7136\u4f1a\u62a5\u9519"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"export HDFS_NAMENODE_USER=root\nexport HDFS_DATANODE_USER=root\nexport HDFS_SECONDARYNAMENODE_USER=root\nexport YARN_RESOURCEMANAGER_USER=root\nexport YARN_NODEMANAGER_USER=root\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u683c\u5f0f\u5316\u6587\u4ef6\u7cfb\u7edf"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"bin/hdfs namenode -format\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8fd0\u884c"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# sbin/start-dfs.sh\nStarting namenodes on [localhost]\nStarting datanodes\nStarting secondary namenodes [ubuntu0]\nubuntu0: Warning: Permanently added 'ubuntu0,192.168.56.3' (ECDSA) to the list of known hosts.\n# jps\n4488 NameNode\n4843 SecondaryNameNode\n4635 DataNode\n4973 Jps\n\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\u914d\u7f6e",children:"\u914d\u7f6e"}),"\n",(0,a.jsx)(n.p,{children:"\u6982\u5ff5\uff1a"}),"\n",(0,a.jsxs)(n.p,{children:["NameNode \u4e3b\u8282\u70b9\u7ba1\u7406\u8005",(0,a.jsx)(n.br,{}),"\n","DataNode \u4ece\u8282\u70b9\u5de5\u4f5c\u8005",(0,a.jsx)(n.br,{}),"\n","SecondaryNameNode \u4e3b\u8282\u70b9\u8f85\u52a9\u8005"]}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e\u6587\u4ef6\uff1a"}),"\n",(0,a.jsx)(n.p,{children:"\u6587\u4ef6\u5939 etc/hadoop/"}),"\n",(0,a.jsxs)(n.p,{children:["workers\uff1a \u4ece\u8282\u70b9 DataNode \u6709\u54ea\u4e9b",(0,a.jsx)(n.br,{}),"\n","hadoop-env.sh \u76f8\u5173\u73af\u5883\u53d8\u91cf",(0,a.jsx)(n.br,{}),"\n","core-site.xml \u6838\u5fc3\u914d\u7f6e\u6587\u4ef6",(0,a.jsx)(n.br,{}),"\n","hdfs-site.xml HDFS \u6838\u5fc3\u914d\u7f6e\u6587\u4ef6"]}),"\n",(0,a.jsx)(n.p,{children:"\u4e09\u53f0\u865a\u62df\u673a node0 node1 node2\uff0c\u914d\u7f6e\u597d\u7f51\u7edc hostonly \u4ee5\u4fbf\u80fd\u8bbf\u95ee\u5f7c\u6b64\uff0c\u751f\u6210\u5bc6\u94a5\u5e76\u628a\u516c\u94a5\u653e\u5165 ~/.ssh/authorized_keys \uff0c\u914d\u7f6e\u597d /etc/hosts"}),"\n",(0,a.jsx)(n.p,{children:"\u4fee\u6539 etc/hadoop \u4e0b\u7684\u914d\u7f6e\u6587\u4ef6"}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e workers"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"vim wokers\nnode0\nnode1\nnode2\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u4fee\u6539 hadoop-env.sh \u914d\u7f6e\u73af\u5883\u53d8\u91cf"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"export JAVA_HOME=/server/jdk1.8.0_202\nexport HADOOP_HOME=/server/hadoop-3.3.5\nexport HADOOP_CONF_DIR=@HADOOP_HOME/etc/hadoop\nexport HADOOP_LOG_DIR=@HADOOP_HOME/logs\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e core-site.xml"}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e HDFS \u6587\u4ef6\u7cfb\u7edf\u7684\u7f51\u7edc\u901a\u8baf\u8def\u5f84"}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e namenode \u4e3a node0 \uff0c\u7f13\u51b2\u533a\u5927\u5c0f\u4e3a 131072"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<configuration>\n    <property>\n        <name>fs.defaultFS</name>\n        <value>hdfs://node0:8020</value>\n    </property>\n    <property>\n        <name>io.file.buffer.size</name>\n        <value>4096</value>\n    </property>\n</configuration>\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e hdfs-site.xml"}),"\n",(0,a.jsx)(n.p,{children:"\u4f9d\u6b21\u4e3a\u9ed8\u8ba4\u6587\u4ef6\u6743\u9650\uff0cnamenode \u5143\u6570\u636e\u5b58\u50a8\u4f4d\u7f6e\uff0cnamenode \u5141\u8bb8\u54ea\u51e0\u53f0\u8282\u70b9\u8fde\u63a5\uff0chdfs\u9ed8\u8ba4\u5757\u5927\u5c0f\uff0cnamenode \u5e76\u53d1\u7ebf\u7a0b\u6570\uff0c\u4ece\u8282\u70b9 datanode \u6570\u636e\u5b58\u50a8\u76ee\u5f55"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<configuration>\n    <property>\n        <name>dfs.datanode.data.dir.perm</name>\n        <value>700</value>\n    </property>\n    <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>/server/nn</value>\n    </property>\n    <property>\n        <name>dfs.namenode.hosts</name>\n        <value>node0,node1,node2</value>\n    </property>\n    <property>\n        <name>dfs.blocksize</name>\n        <value>134217728</value>\n    </property>\n    <property>\n        <name>dfs.namenode.handler.count</name>\n        <value>100</value>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>/server/dn</value>\n    </property>\n</configuration>\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"vim /etc/profile\n\nexport JAVA_HOME=/server/jdk1.8.0_202\nexport HADOOP_HOME=/server/hadoop-3.3.5\nexport PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH\n\nsource /etc/profile\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u590d\u5236\u914d\u7f6e\u6587\u4ef6"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"scp workers wjf@192.168.56.8:/server/hadoop-3.3.5/etc/hadoop/\nscp workers wjf@192.168.56.9:/server/hadoop-3.3.5/etc/hadoop/\nscp hadoop-env.sh wjf@192.168.56.8:/server/hadoop-3.3.5/etc/hadoop/\nscp hadoop-env.sh wjf@192.168.56.9:/server/hadoop-3.3.5/etc/hadoop/\nscp core-site.xml wjf@192.168.56.8:/server/hadoop-3.3.5/etc/hadoop/\nscp core-site.xml wjf@192.168.56.9:/server/hadoop-3.3.5/etc/hadoop/\nscp hdfs-site.xml wjf@192.168.56.8:/server/hadoop-3.3.5/etc/hadoop/\nscp hdfs-site.xml wjf@192.168.56.9:/server/hadoop-3.3.5/etc/hadoop/\n"})}),"\n",(0,a.jsx)(n.p,{children:"node0 \u683c\u5f0f\u5316 namenode"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'# hadoop namenode -format\nWARNING: Use of this script to execute namenode is deprecated.\nWARNING: Attempting to execute replacement "hdfs namenode" instead.\n\n2023-05-16 22:24:41,711 INFO namenode.NameNode: STARTUP_MSG: \n/************************************************************\nSTARTUP_MSG: Starting NameNode\nSTARTUP_MSG:   host = debian0/127.0.1.1\nSTARTUP_MSG:   args = [-format]\nSTARTUP_MSG:   version = 3.3.5\n...\n2023-05-16 22:24:45,336 INFO namenode.FSImageFormatProtobuf: Image file /server/nn/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .\n2023-05-16 22:24:45,368 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n2023-05-16 22:24:45,408 INFO namenode.FSNamesystem: Stopping services started for active state\n2023-05-16 22:24:45,410 INFO namenode.FSNamesystem: Stopping services started for standby state\n2023-05-16 22:24:45,415 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\n2023-05-16 22:24:45,418 INFO namenode.NameNode: SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down NameNode at debian0/127.0.1.1\n************************************************************/\n'})}),"\n",(0,a.jsx)(n.p,{children:"\u542f\u52a8 namenode"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@debian0:/server$ start-dfs.sh\nStarting namenodes on [node0]\nStarting datanodes\nStarting secondary namenodes [debian0]\nwjf@debian0:/server$ jps\n3856 Jps\n3740 SecondaryNameNode\n3613 DataNode\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"datanode \u4e5f\u88ab\u542f\u52a8"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# jps\n1590 DataNode\n1640 Jps\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8bbf\u95ee node0:9870 \u53ef\u4ee5\u770b\u5230\u7ba1\u7406\u754c\u9762"}),"\n",(0,a.jsx)(n.h3,{id:"hdfs",children:"HDFS"}),"\n",(0,a.jsx)(n.p,{children:"HDFS \u662f hadoop \u7684\u5206\u5e03\u5f0f\u5b58\u50a8\u7ec4\u5efa"}),"\n",(0,a.jsxs)(n.p,{children:["\u5168\u542f\u5168\u505c\uff1a start-dfs.sh stop-dfs.sh\n\u5355\u72ec\u8fdb\u7a0b\u542f\u52a8\u505c\u6b62\uff1a ",(0,a.jsx)(n.code,{children:"hdfs --daemon (stat|stop|status) (namenode|datanode|secondarynamenode)"})]}),"\n",(0,a.jsx)(n.p,{children:"\u533a\u5206\u6587\u4ef6\u7cfb\u7edf\uff08hadoop\u53ef\u4ee5\u81ea\u52a8\u8bc6\u522b\uff09"}),"\n",(0,a.jsx)(n.p,{children:"Linux:  file///usr/local/a.txt\nHDFS:  hdfs://node1:9020/usr/local/a.txt"}),"\n",(0,a.jsxs)(n.p,{children:["\u8001\u7248\u672c\u547d\u4ee4 ",(0,a.jsx)(n.code,{children:"hadoop fs [generic options]"})," \uff0c\u65b0\u7248\u672c ",(0,a.jsx)(n.code,{children:"hdfs dfs [generic options]"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@node0:/server/hadoop-3.3.5$ hdfs dfs -mkdir -p /home/a\n\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -ls -h -R /\ndrwxr-xr-x   - wjf supergroup          0 2023-05-17 22:03 /home\ndrwxr-xr-x   - wjf supergroup          0 2023-05-17 22:03 /home/a\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u4e0a\u4f20 \u4e0b\u8f7d \u590d\u5236"}),"\n",(0,a.jsxs)(n.p,{children:["\u4e0a\u4f20\u53ef\u4ee5\u901a\u8fc7 ",(0,a.jsx)(n.code,{children:"-D dfs.replication=2"})," \u4e34\u65f6\u4fee\u6539\u526f\u672c"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"hdfs dfs -put [-f] [-p] <localsrc>...  <dest>\n\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -put README.txt hdfs://node0:8020/\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -put -D dfs.replication=2 README.txt hdfs://node0:8020/\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -cat /README.txt\nFor the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/\n\nand our wiki, at:\n\n   https://cwiki.apache.org/confluence/display/HADOOP/\n\n# \u590d\u5236 hdfs dfs -cp [-f] <source> <dest> \uff08\u4e24\u4e2a\u8def\u5f84\u90fd\u662f hdfs\uff09\nhdfs dfs -cp /README.txt /README2.txt\n\n# hdfs dfs -get [-f] [-p] <localsrc>...  <dest>\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -get /README2.txt .\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8ffd\u52a0\u5230\u6587\u4ef6\uff08\u6587\u4ef6\u65e0\u6cd5\u7f16\u8f91\uff0c\u53ea\u80fd\u591f\u5220\u9664\u548c\u8ffd\u52a0\uff09"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'wjf@node0:/server/hadoop-3.3.5$ echo "aaa" >> 1.txt\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -appendToFile 1.txt /README.txt\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -cat /README.txt\nFor the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/\n\nand our wiki, at:\n\n   https://cwiki.apache.org/confluence/display/HADOOP/\naaa\n'})}),"\n",(0,a.jsx)(n.p,{children:"\u6587\u4ef6\u7684\u79fb\u52a8\uff08\u6216\u6539\u540d\uff09\u548c\u5220\u9664"}),"\n",(0,a.jsx)(n.p,{children:"\u5220\u9664 -rm \uff0c skipTrash \u8868\u793a\u8df3\u8fc7\u56de\u6536\u7ad9\uff0c\u4f46\u56de\u6536\u7ad9\u9ed8\u8ba4\u662f\u4e0d\u5f00\u542f\u7684\uff0c\u9ed8\u8ba4\u60c5\u51b5\u65e0\u9700 skipTrash \u5373\u53ef\u6c38\u4e45\u5220\u9664"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@node0:/server/hadoop-3.3.5$ hdfs dfs -mv /README.txt /home\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -ls -h -R /\n-rw-r--r--   3 wjf supergroup        175 2023-05-17 22:20 /README2.txt\ndrwxr-xr-x   - wjf supergroup          0 2023-05-17 22:35 /home\n-rw-r--r--   3 wjf supergroup        179 2023-05-17 22:33 /home/README.txt\ndrwxr-xr-x   - wjf supergroup          0 2023-05-17 22:03 /home/a\n\n# \u5220\u9664 hdfs dfs -rm [-r] [-skipTrash] <src>\nwjf@node0:/server/hadoop-3.3.5$ hdfs dfs -rm -r /home\nDeleted /home\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u66f4\u591a\u547d\u4ee4\u53ef\u4ee5\u53c2\u8003 ",(0,a.jsx)(n.a,{href:"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html",children:"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html"})]}),"\n",(0,a.jsxs)(n.p,{children:["\u9664\u4e86\u4f7f\u7528\u547d\u4ee4\uff0c\u4e5f\u53ef\u4ee5\u7528 web-ui ",(0,a.jsx)(n.a,{href:"http://node0:9870/explorer.html#/",children:"http://node0:9870/explorer.html#/"})," \uff0c\u7f51\u9875\u7684\u6743\u9650\u662f dr.who \u662f\u6ca1\u6709\u6743\u9650\u64cd\u4f5c\u7684\uff0c\u53ef\u4ee5\u901a\u8fc7\u914d\u7f6e\u6587\u4ef6\u8d4b\u4e88\u67d0\u4e2a\u7528\u6237\u7684\u6743\u9650\uff0c\u4f46\u662f\u4e0d\u5b89\u5168"]}),"\n",(0,a.jsxs)(n.p,{children:["\u67e5\u770b\u96c6\u7fa4\u6587\u4ef6\u526f\u672c\u3002\u9ed8\u8ba4\u6587\u4ef6\u6309 block \u5206\u5272\uff0c\u9ed8\u8ba4 256MB\uff0c \u9ed8\u8ba4\u6bcf\u4e2a\u5757 3 \u4e2a\u526f\u672c\uff0c\u53ef\u4ee5\u901a\u8fc7 ",(0,a.jsx)(n.code,{children:"dfs.replication"})," \u914d\u7f6e\u526f\u672c\u6570"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@node0:~$ hdfs fsck /wjf/aa/hosts -files -blocks -locations\nConnecting to namenode via http://node0:9870/fsck?ugi=wjf&files=1&blocks=1&locations=1&path=%2Fwjf%2Faa%2Fhosts\nFSCK started by wjf (auth:SIMPLE) from /192.168.56.7 for path /wjf/aa/hosts at Thu May 18 20:53:52 CST 2023\n\n/wjf/aa/hosts 228 bytes, replicated: replication=3, 1 block(s):  OK\n0. BP-1743682380-127.0.1.1-1684248434454:blk_1073741827_1005 len=228 Live_repl=3  [DatanodeInfoWithStorage[192.168.56.7:9866,DS-4f33e3c9-e8e1-4d70-b3dd-3de2882ecd31,DISK], DatanodeInfoWithStorage[192.168.56.9:9866,DS-03fb8214-a502-4a27-8ba0-5c7c18636708,DISK], DatanodeInfoWithStorage[192.168.56.8:9866,DS-3073fa17-c53e-49fe-b29a-6adf9dc840eb,DISK]]\n\nStatus: HEALTHY\n Number of data-nodes:\t3\n Number of racks:\t\t1\n Total dirs:\t\t\t0\n Total symlinks:\t\t0\n\nReplicated Blocks:\n Total size:\t228 B\n Total files:\t1\n Total blocks (validated):\t1 (avg. block size 228 B)\n Minimally replicated blocks:\t1 (100.0 %)\n Over-replicated blocks:\t0 (0.0 %)\n Under-replicated blocks:\t0 (0.0 %)\n Mis-replicated blocks:\t\t0 (0.0 %)\n Default replication factor:\t3\n Average block replication:\t3.0\n Missing blocks:\t\t0\n Corrupt blocks:\t\t0\n Missing replicas:\t\t0 (0.0 %)\n Blocks queued for replication:\t0\n\nErasure Coded Block Groups:\n Total size:\t0 B\n Total files:\t0\n Total block groups (validated):\t0\n Minimally erasure-coded block groups:\t0\n Over-erasure-coded block groups:\t0\n Under-erasure-coded block groups:\t0\n Unsatisfactory placement block groups:\t0\n Average block group size:\t0.0\n Missing block groups:\t\t0\n Corrupt block groups:\t\t0\n Missing internal blocks:\t0\n Blocks queued for replication:\t0\nFSCK ended at Thu May 18 20:53:52 CST 2023 in 16 milliseconds\n\n\nThe filesystem under path '/wjf/aa/hosts' is HEALTHY\n\n"})}),"\n",(0,a.jsxs)(n.p,{children:["edits \u6587\u4ef6\u8bb0\u5f55 hdfs \u6bcf\u4e00\u6b21\u64cd\u4f5c\uff0cedits \u8fbe\u5230\u4e0a\u9650\u5927\u5c0f\u540e\u4f1a\u5f00\u542f\u65b0\u7684\u6587\u4ef6\u8bb0\u5f55\u3002FSImage \u6587\u4ef6\u662f edits \u64cd\u4f5c\u7684\u5408\u5e76\uff08\u67d0\u4e2a\u65f6\u95f4\u8282\u70b9\u524d\u7684\u5168\u90e8\u6587\u4ef6\u72b6\u6001\u4fe1\u606f\uff09\uff0c\u4f1a\u5b9a\u671f\u5c06\u5168\u90e8 edits \u6587\u4ef6\u4e0e fsimage \u5408\u5e76\u5f62\u6210\u65b0\u7684 fsimage \u3002\u6587\u4ef6\u5b58\u653e\u5728 ",(0,a.jsx)(n.code,{children:"dfs.datanode.data.dir"})," \uff0c\u9ed8\u8ba4 1 \u5c0f\u65f6\u6216 100 \u4e07\u4e8b\u52a1\u4f1a\u5408\u5e76\u5143\u6570\u636e\uff0c\u5408\u5e76\u64cd\u4f5c\u7531 secondarynamenode \u6267\u884c"]}),"\n",(0,a.jsx)(n.p,{children:"\u5199\u5165\u6d41\u7a0b\uff1a"}),"\n",(0,a.jsx)(n.p,{children:"\u5ba2\u6237\u7aef\u53d1\u9001\u8bf7\u6c42\u5230 namenode \u3002namenode \u5ba1\u6838\uff0c\u82e5\u6ee1\u8db3\u6761\u4ef6\u5141\u8bb8\u5199\u5165\uff0c\u544a\u77e5\u5ba2\u6237\u7aef\u5199\u5165\u7684 datanode \u5730\u5740\u3002\u5ba2\u6237\u7aef\u5411 datanode \u53d1\u9001\u6570\u636e\u5305\u3002datanode \u540c\u65f6\u5b8c\u6210\u526f\u672c\u590d\u5236\u5de5\u4f5c\uff0c\u5e76\u5c06\u6570\u636e\u53d1\u7ed9\u5176\u4ed6 datanode\u3002\u5199\u5165\u5b8c\u6210\u540e\u901a\u77e5 namenode\uff0c namenode \u8bb0\u5f55\u5143\u6570\u636e\u3002"}),"\n",(0,a.jsx)(n.p,{children:"namenode \u4e0d\u8d1f\u8d23\u5199\u5165\uff0c\u53ea\u8d1f\u8d23\u8bb0\u5f55\u5143\u6570\u636e\u548c\u5ba1\u6279\u6743\u9650\u3002datanode \u5199\u6570\u636e\uff0c\u4f46\u5ba2\u6237\u7aef\u53ea\u9700\u5411\u5176\u4e2d\u4e00\u53f0 datanode \u53d1\u9001\uff0c\u526f\u672c\u590d\u5236\u7531 datanode \u4e4b\u95f4\u81ea\u884c\u5b8c\u6210\u3002"}),"\n",(0,a.jsx)(n.p,{children:"\u8bfb\u53d6\u6d41\u7a0b\uff1a"}),"\n",(0,a.jsx)(n.p,{children:"\u5ba2\u6237\u7aef\u53d1\u9001\u8bfb\u53d6\u8bf7\u6c42\uff0c namenode \u5141\u8bb8\u5e76\u544a\u77e5 block \u5217\u8868\uff0c\u5ba2\u6237\u7aef\u6839\u636e block \u5217\u8868\u81ea\u884c\u4ece datanode \u8bfb\u53d6\u6240\u9700\u7684 block"}),"\n",(0,a.jsx)(n.p,{children:"namenode \u63d0\u4f9b\u7684 block \u4f1a\u6839\u636e\u7f51\u7edc\u8ddd\u79bb\u8ba1\u7b97\uff0c\u5c3d\u91cf\u79bb\u5ba2\u6237\u7aef\u8fd1"}),"\n",(0,a.jsx)(n.h3,{id:"mapreduce-\u548c-yarn",children:"MapReduce \u548c Yarn"}),"\n",(0,a.jsx)(n.p,{children:"\u5206\u6563 - \u6c47\u603b"}),"\n",(0,a.jsx)(n.p,{children:"MapReduce \u662f\u57fa\u4e8e YARN \u8fd0\u884c\u7684\uff0cYARN \u662f\u8d44\u6e90\u8c03\u5ea6\u7ec4\u4ef6\u3002"}),"\n",(0,a.jsx)(n.p,{children:"YARN \u67b6\u6784\uff1a \u4e3b\u4ece\u67b6\u6784\uff0c\u4e3b\uff08master\uff09\u89d2\u8272\uff1aResourceManager \u6574\u4e2a\u96c6\u7fa4\u7684\u8d44\u6e90\u8c03\u5ea6\u7740\uff0c\u4ece\uff08slave\uff09\u89d2\u8272\uff1aNodeManager \u5355\u4e2a\u670d\u52a1\u7684\u8c03\u5ea6\u8005\uff0c\u63a5\u53d7 Resource Manager \u7684\u4efb\u52a1\uff0c\u521b\u5efa\u5bb9\u5668\uff0c\u56de\u6536\u8d44\u6e90\u3002"}),"\n",(0,a.jsx)(n.p,{children:"node0 \u642d\u5efa ResourceManager NodeManager ProxyServer JobHistoryServer \uff0c node1 node2 \u642d\u5efa NodeManager"}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e mapreduce"}),"\n",(0,a.jsx)(n.p,{children:"mapred-env.sh"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"export JAVA_HOME=/server/jdk1.8.0_202\n# JobHistoryServer \u8fdb\u7a0b\u5185\u5b58\nexport HADOOP_JOB_HISTORYSERVER_HEAPSIZE=256\n# \u65e5\u5fd7\u7ea7\u522b\nexport HADOOP_MAPRED_ROOT_LOGGER=INFO,RFA\n"})}),"\n",(0,a.jsx)(n.p,{children:"mapred-site.xml"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<property>\n    <name>mapreduce.framework.name</name>\n    <value>yarn</value>\n    <description>\u8fd0\u884c\u6846\u67b6\u8bbe\u7f6e\u4e3ayarn</description>\n</property>\n<property>\n    <name>mapreduce.jobhistory.address</name>\n    <value>node0:10020</value>\n    <description>JobHistoryServer</description>\n</property>\n\n<property>\n  <name>yarn.app.mapreduce.am.env</name>\n  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>\n</property>\n<property>\n  <name>mapreduce.map.env</name>\n  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>\n</property>\n<property>\n  <name>mapreduce.reduce.env</name>\n  <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>\n</property>\n"})}),"\n",(0,a.jsx)(n.p,{children:"yarn-env.sh"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-shell",children:"export JAVA_HOME=/server/jdk1.8.0_202\nexport HADOOP_HOME=/server/hadoop-3.3.5\nexport HADOOP_CONFIG_DIR=${HADOOP_HOME}/etc/hadoop\nexport HADOOP_LOG_DIR=${HADOOP_HOME}/logs\n"})}),"\n",(0,a.jsx)(n.p,{children:"yarn-site.xml"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"  <property>\n    <name>yarn.resourcemanager.hostname</name>\n    <value>node0</value>\n    <description></description>\n  </property>\n\n  <property>\n    <name>yarn.nodemanager.local-dirs</name>\n    <value>/server/nm-local</value>\n    <description>nodemanager\u4e2d\u95f4\u6570\u636e\u5b58\u50a8\u8def\u5f84</description>\n  </property>\n\n  <property>\n    <name>yarn.nodemanager.log-dirs</name>\n    <value>/server/nm-log</value>\n    <description>nodemanager\u6570\u636e\u65e5\u5fd7\u672c\u5730\u5b58\u50a8\u8def\u5f84</description>\n  </property>\n\n  <property>\n    <name>yarn.nodemanager.aux-services</name>\n    <value>mapreduce_shuffle</value>\n    <description>\u4e3amapreduce\u5f00\u542fshuffle\u670d\u52a1</description>\n  </property>\n\n  <property>\n    <name>yarn.log.server.url</name>\n    <value>http://node0:19888/jobhistory/logs</value>\n    <description>\u5386\u53f2\u670d\u52a1\u5668url</description>\n  </property>\n\n  <property>\n    <name>yarn.web.proxy.address</name>\n    <value>hode0:8089</value>\n    <description>\u4ee3\u7406\u670d\u52a1\u5668</description>\n  </property>\n  <property>\n    <name>yarn.log.aggregation-enable</name>\n    <value>true</value>\n    <description>\u65e5\u5fd7\u805a\u5408</description>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>/tmp/logs</value>\n    <description>\u7a0b\u5e8f\u65e5\u5fd7HDFS\u5b58\u50a8\u8def\u5f84</description>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.class</name>\n    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>\n    <description>\u9009\u62e9\u516c\u5e73\u8c03\u5ea6\u5668</description>\n  </property>\n\n  \n\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u590d\u5236\u914d\u7f6e\u6587\u4ef6"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ scp mapred-env.sh mapred-site.xml yarn-env.sh yarn-site.xml node1:`pwd`/ \n$ scp mapred-env.sh mapred-site.xml yarn-env.sh yarn-site.xml node2:`pwd`/\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# \u96c6\u7fa4\u542f\u52a8\nstart-yarn.sh\n# \u96c6\u7fa4\u505c\u6b62\nstop-yarn.sh\n\n# \u5355\u53f0\u64cd\u4f5c\nyarn --daemon start|stop resourcemanager|nodemanager|proxyserver\n\n# \u5386\u53f2\u670d\u52a1\u5668\u542f\u52a8\u548c\u505c\u6b62\n#mapred --daemon start|stop historyserver\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ jps\n2081 NodeManager\n1235 DataNode\n1141 NameNode\n1365 SecondaryNameNode\n2535 Jps\n2474 JobHistoryServer\n1994 ResourceManager\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u53ef\u4ee5\u901a\u8fc7 ",(0,a.jsx)(n.a,{href:"http://node0:8088/",children:"http://node0:8088/"})," \u67e5\u770b yarn \u9875\u9762\uff0c",(0,a.jsx)(n.a,{href:"http://node0:19888/",children:"http://node0:19888/"})," \u53ef\u4ee5\u67e5\u770b historyserver \u9875\u9762"]}),"\n",(0,a.jsx)(n.p,{children:"yarn \u542f\u52a8\u65f6\u4ece yarn-site.xml \u8bfb\u53d6\u914d\u7f6e\uff0c\u786e\u5b9a ResourceManager \u6240\u5728\u673a\u5668\uff0c\u542f\u52a8\u5b83\u3002\u8bfb\u53d6 workers \u6587\u4ef6\uff0c\u542f\u52a8\u5168\u90e8 NodeManager\u3002\u5728\u5f53\u524d\u673a\u5668\u542f\u52a8 ProxyServer"}),"\n",(0,a.jsx)(n.p,{children:"yarn \u53ef\u4ee5\u8fd0\u884c MapReduce \u3001 Spark \u3001 Flink \u7a0b\u5e8f"}),"\n",(0,a.jsx)(n.p,{children:"mapreduce \u542f\u52a8\u547d\u4ee4"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"hadoop jar [\u7a0b\u5e8f\u6587\u4ef6] [java\u7c7b\u540d] [\u53c2\u65701] [\u53c2\u65702]\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8bd5\u7740\u8fd0\u884c\u4e00\u4e0b mapreduce \u7a0b\u5e8f\u3002\u5728 hdfs \u4e2d\u653e\u7f6e\u4e00\u4e2a\u6587\u672c\u6587\u4ef6\u5728 /input \u76ee\u5f55\uff0c\u8fd0\u884c wordcount"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ hadoop jar /server/hadoop-3.3.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.5.jar wordcount hdfs://node0:8020/input hdfs://node0:8020/output/wc\n2023-05-22 22:14:16,556 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at node0/192.168.56.7:8032\n2023-05-22 22:14:17,355 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/wjf/.staging/job_1684762859481_0003\n2023-05-22 22:14:17,781 INFO input.FileInputFormat: Total input files to process : 1\n2023-05-22 22:14:17,927 INFO mapreduce.JobSubmitter: number of splits:1\n2023-05-22 22:14:18,171 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1684762859481_0003\n2023-05-22 22:14:18,171 INFO mapreduce.JobSubmitter: Executing with tokens: []\n2023-05-22 22:14:18,400 INFO conf.Configuration: resource-types.xml not found\n2023-05-22 22:14:18,402 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n2023-05-22 22:14:18,482 INFO impl.YarnClientImpl: Submitted application application_1684762859481_0003\n2023-05-22 22:14:18,561 INFO mapreduce.Job: The url to track the job: http://node0:8088/proxy/application_1684762859481_0003/\n2023-05-22 22:14:18,562 INFO mapreduce.Job: Running job: job_1684762859481_0003\n2023-05-22 22:14:27,908 INFO mapreduce.Job: Job job_1684762859481_0003 running in uber mode : false\n2023-05-22 22:14:27,924 INFO mapreduce.Job:  map 0% reduce 0%\n2023-05-22 22:14:36,064 INFO mapreduce.Job:  map 100% reduce 0%\n2023-05-22 22:14:44,165 INFO mapreduce.Job:  map 100% reduce 100%\n2023-05-22 22:14:45,193 INFO mapreduce.Job: Job job_1684762859481_0003 completed successfully\n...\n\tFile Input Format Counters \n\t\tBytes Read=49\n\tFile Output Format Counters \n\t\tBytes Written=48\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u67e5\u770b\u7ed3\u679c"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@node0:/server/hadoop-3.3.5/etc/hadoop$ hdfs dfs -ls -R -h /output\ndrwxr-xr-x   - wjf supergroup          0 2023-05-22 22:14 /output/wc\n-rw-r--r--   3 wjf supergroup          0 2023-05-22 22:14 /output/wc/_SUCCESS\n-rw-r--r--   3 wjf supergroup         48 2023-05-22 22:14 /output/wc/part-r-00000\nwjf@node0:/server/hadoop-3.3.5/etc/hadoop$ hdfs dfs -cat /output/wc/part-r-00000\nafternoon\t1\nbye\t1\ngood\t3\nhello\t1\nhi\t2\nmorning\t1\n"})}),"\n",(0,a.jsx)(n.p,{children:"3 \u4e2a\u8282\u70b9 10000 \u6837\u672c\u8499\u7279\u5361\u7f57\u6c42\u5706\u5468\u7387"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@node0:/server/hadoop-3.3.5$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.5.jar pi 3 10000\nNumber of Maps  = 3\nSamples per Map = 10000\nWrote input for Map #0\nWrote input for Map #1\nWrote input for Map #2\nStarting Job\n2023-05-22 22:33:32,244 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at node0/192.168.56.7:8032\n2023-05-22 22:33:32,789 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/wjf/.staging/job_1684762859481_0005\n2023-05-22 22:33:33,000 INFO input.FileInputFormat: Total input files to process : 3\n2023-05-22 22:33:33,113 INFO mapreduce.JobSubmitter: number of splits:3\n...\nJob Finished in 29.323 seconds\nEstimated value of Pi is 3.14146666666666666667\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5b9e\u73b0\u5206\u5e03\u5f0f\u8ba1\u7b97\u662f\u4e0d\u5bb9\u6613\u7684\uff0cMapReduce \u53ef\u4ee5\u8ba9\u6211\u4eec\u901a\u8fc7\u5b9e\u73b0\u63a5\u53e3\u7684\u65b9\u5f0f\u5b8c\u6210\u4e1a\u52a1\u903b\u8f91\uff0c\u65e0\u9700\u7ba1\u7406\u8d44\u6e90\uff0c\u5177\u6709\u5bb9\u9519\u6027\u3002MapReduce \u4e0d\u64c5\u957f\u5b9e\u65f6\u54cd\u5e94\u7684\u8ba1\u7b97\uff0c\u4e0d\u64c5\u957f\u4e32\u884c\u8ba1\u7b97\u3002"}),"\n",(0,a.jsx)(n.p,{children:"MrAppMaster \u8d1f\u8d23\u8c03\u5ea6\u548c\u72b6\u6001\u534f\u8c03\uff0cMapTask \u8d1f\u8d23\u6574\u4e2a\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0cReduceTask \u8d1f\u8d23 Reduce \u9636\u6bb5\u6570\u636e\u5904\u7406"}),"\n",(0,a.jsx)(n.p,{children:"\u4f9d\u8d56"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<dependency>\n    <groupId>org.apache.hadoop</groupId>\n    <artifactId>hadoop-client</artifactId>\n    <version>3.1.3</version>\n</dependency>\n\n<dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.12</version>\n</dependency>\n\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-log4j12</artifactId>\n    <version>1.7.30</version>\n</dependency>\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u4e00\u4e2a word count \u793a\u4f8b\u7a0b\u5e8f"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'import org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Mapper;\n\nimport java.io.IOException;\n\npublic class WordCountMapper extends Mapper<LongWritable, Text,Text, IntWritable> {\n\n    private Text outK = new Text();\n    private IntWritable outV = new IntWritable();\n\n    @Override\n    protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context) throws IOException, InterruptedException {\n        String line = value.toString();\n\n        String[] words = line.split(" ");\n\n        for(String w: words) {\n            outK.set(w);\n            outV.set(1);\n            context.write(outK, outV);\n        }\n    }\n}\n'})}),"\n",(0,a.jsx)(n.p,{children:"Reducer"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:"import org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Reducer;\n\nimport java.io.IOException;\n\npublic class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n\n    IntWritable outV = new IntWritable();\n    @Override\n    protected void reduce(Text key, Iterable<IntWritable> values, Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {\n        int sum = 0;\n        for(IntWritable value: values) {\n            sum += value.get();\n        }\n        outV.set(sum);\n        context.write(key, outV);\n    }\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"Driver"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-java",children:'\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\nimport java.io.IOException;\n\npublic class WordCountDriver {\n    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {\n        //1 \u83b7\u53d6job\n        Configuration conf = new Configuration();\n        Job job = Job.getInstance(conf);\n\n        // 2 \u8bbe\u7f6e jar \u8def\u5f84\n        job.setJarByClass(WordCountDriver.class);\n\n        // 3 \u5173\u8054 mapper \u548c reducer\n        job.setMapperClass(WordCountMapper.class);\n        job.setReducerClass(WordCountReducer.class);\n\n        // 4 \u8bbe\u7f6e map \u8f93\u51fa\u7684 k v \u7c7b\u578b\n        job.setMapOutputKeyClass(Text.class);\n        job.setMapOutputValueClass(IntWritable.class);\n\n        // 5 \u8bbe\u7f6e\u6700\u7ec8\u8f93\u51fa\u7684 k v \u7c7b\u578b\n        job.setOutputKeyClass(Text.class);\n        job.setOutputValueClass(IntWritable.class);\n\n        // 6 \u8bbe\u7f6e\u8f93\u5165\u8f93\u51fa\u8def\u5f84\n        FileInputFormat.setInputPaths(job, new Path("src/main/resources/input"));\n        FileOutputFormat.setOutputPath(job, new Path("src/main/resources/output"));\n\n        // 7 \u63d0\u4ea4 job\n        // \u76d1\u63a7\u5e76\u6253\u5370\u4fe1\u606f\n        boolean result = job.waitForCompletion(true);\n\n        System.exit(result ? 0 : 1);\n\n    }\n\n}\n'})}),"\n",(0,a.jsx)(n.p,{children:"\u8f93\u51fa\u6587\u4ef6\uff1a"}),"\n",(0,a.jsx)(n.p,{children:"_SUCCESS \u4e3a\u4fe1\u53f7\u6587\u4ef6\uff0c\u8868\u793a\u7ed3\u679c\u6210\u529f\uff0cpart-r-00000 \u4e3a 00000 \u5206\u533a\u7684\u7ed3\u679c"}),"\n",(0,a.jsx)(n.p,{children:"\u5728 hadoop \u96c6\u7fa4\u4e0a\u8fd0\u884c\uff1amaven \u6253\u5305\uff08\u65e0\u9700\u5e26\u4f9d\u8d56\uff0c\u56e0\u4e3a hadoop \u96c6\u7fa4\u4e0a\u6709\u9700\u8981\u7684\u4f9d\u8d56\uff09\uff0c\u5c06 jar \u5305\u653e\u5230\u8282\u70b9\u4e0a\uff0c\u5c06\u6570\u636e\u653e\u5165\u8f93\u5165\u8def\u5f84\uff0c\u786e\u4fdd\u8f93\u51fa\u8def\u5f84\u4e3a\u7a7a"}),"\n",(0,a.jsx)(n.p,{children:"\u8fd0\u884c\uff0c\u6307\u5b9a jar \u5305\u548c\u5168\u7c7b\u540d"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"hadoop jar wordcount.jar com.wjftu.WordCountDriver\n"})}),"\n",(0,a.jsx)(n.h3,{id:"hive",children:"Hive"}),"\n",(0,a.jsx)(n.p,{children:"Metastore \u7528\u4e8e\u5143\u6570\u636e\u5b58\u50a8"}),"\n",(0,a.jsx)(n.p,{children:"Driver \u9a71\u52a8\u7a0b\u5e8f\u5b8c\u6210 sql \u89e3\u6790\uff0c\u6267\u884c\u4f18\u5316\uff0c\u4ee3\u7801\u63d0\u4ea4"}),"\n",(0,a.jsx)(n.p,{children:"\u7528\u6237\u63a5\u53e3\u63d0\u4f9b\u7528\u6237\u4ea4\u4e92\u529f\u80fd"}),"\n",(0,a.jsx)(n.p,{children:"Hive \u662f\u5355\u673a\u5de5\u5177\uff0c\u4f46\u53ef\u4ee5\u63d0\u4ea4\u5230\u5206\u5e03\u5f0f\u7684 MapReduce \u7a0b\u5e8f\u8fd0\u884c"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wget https://dev.mysql.com/get/mysql-apt-config_0.8.18-1_all.deb\nsudo dpkg -i mysql-apt-config_0.8.18-1_all.deb\n# \u9009\u62e9 debian buster -> myusql server -> mysql-5.7\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 467B942D3A79BD29\napt update \nsudo apt install -y mysql-community-server\nsystemctl restart mysql\nsystemctl enable mysql\n"})}),"\n",(0,a.jsx)(n.p,{children:"core-site.xml \u6dfb\u52a0\u914d\u7f6e\uff0c\u5141\u8bb8\u4ee3\u7406"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<property>\n    <name>hadoop.proxyuser.hadoop.hosts</name>\n    <value>*</value>\n</property>\n<property>\n    <name>hadoop.proxyuser.hadoop.groups</name>\n    <value>*</value>\n</property>\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://archive.apache.org/dist/",children:"https://archive.apache.org/dist/"})," \u4ece apache archive \u4e0b\u8f7d Hive \uff0c\u4ee5\u53ca Hive \u9700\u8981\u7684 mysql \u9a71\u52a8\u3002Hive \u6709\u5143\u6570\u636e\u7ba1\u7406\u529f\u80fd\uff0c\u9700\u8981\u6570\u636e\u5e93\uff0c\u8fd9\u91cc\u7528 MySql"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wget https://archive.apache.org/dist/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz\nwget https://search.maven.org/remotecontent?filepath=com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar\ntar -zxvf apache-hive-3.1.3-bin.tar.gz \nmv mysql-connector-j-8.0.33.jar apache-hive-3.1.3-bin/lib/\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u521b\u5efa\u6570\u636e\u5e93"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sql",children:"create database hive charset utf8;\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u914d\u7f6e hive-env.sh"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"export HADOOP_HOME=/server/hadoop-3.3.5\nexport HIVE_CONF_DIR=/server/apache-hive-3.1.3-bin/conf\nexport HIVE_AUX_JARS_PATH=/server/apache-hive-3.1.3-bin/lib\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-xml",children:"<configuration>\n    <property>\n        <name>javax.jdo.option.ConnectionURL</name>\n        <value>jdbc:mysql://node0:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false&amp;useUnicode=true&amp;charsetEncoding=UTF-8</value>\n    </property>\n    <property>\n        <name>javax.jdo.option.ConnectionDriverName</name>\n        <value>com.mysql.cj.jdbc.Driver</value>\n    </property>\n    <property>\n        <name>javax.jdo.option.ConnectionUserName</name>\n        <value>root</value>\n    </property>\n    <property>\n        <name>javax.jdo.option.ConnectionPassword</name>\n        <value>123456</value>\n    </property>\n    <property>\n        <name>hive.server2.thrift.bind.host</name>\n        <value>node0</value>\n    </property>\n    <property>\n        <name>hive.metastore.uris</name>\n        <value>thrift://node0:9083</value>\n    </property>\n    <property>\n        <name>hive.metastore.event.db.notification.api.auth</name>\n        <value>false</value>\n    </property>\n</configuration>\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8fd0\u884c bin/schematool \uff0c\u521d\u59cb\u5316\u5143\u6570\u636e\uff0c\u5236\u5b9a\u6570\u636e\u5e93\u4e3a mysql \uff0cverbos \u8868\u793a\u8f93\u51fa\u8be6\u7ec6\u4fe1\u606f"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ ./schematool -initSchema -dbType mysql -verbos\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/server/apache-hive-3.1.3-bin/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/server/hadoop-3.3.5/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\nMetastore connection URL:\t jdbc:mysql://node0:3306/hive?createDatabaseIfNotExist=true&useSSL=false&useUnicode=true&charsetEncoding=UTF-8\nMetastore Connection Driver :\t com.mysql.cj.jdbc.Driver\nMetastore connection User:\t root\nStarting metastore schema initialization to 3.1.0\nInitialization script hive-schema-3.1.0.mysql.sql\n\nInitialization script completed\nschemaTool completed\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u4f1a\u521d\u59cb\u5316\u5f88\u591a\u8868"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"mysql> show tables;\n+-------------------------------+\n| Tables_in_hive                |\n+-------------------------------+\n| AUX_TABLE                     |\n| BUCKETING_COLS                |\n| CDS                           |\n| COLUMNS_V2                    |\n| COMPACTION_QUEUE              |\n...\n| WM_POOL                       |\n| WM_POOL_TO_TRIGGER            |\n| WM_RESOURCEPLAN               |\n| WM_TRIGGER                    |\n| WRITE_SET                     |\n+-------------------------------+\n74 rows in set (0.00 sec)\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u542f\u52a8\u5143\u6570\u636e\u7ba1\u7406\u670d\u52a1\uff08\u4e0d\u7136\u65e0\u6cd5\u4f7f\u7528\uff09\uff0cJps \u663e\u793a\u4e3a RunJar"}),"\n",(0,a.jsx)(n.p,{children:"\uff08\u542f\u52a8\u4e4b\u524d\u65b0\u5efa\u65e5\u5fd7\u6587\u4ef6\u5939 logs\uff09"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# \u524d\u53f0\u542f\u52a8\nbin/hive --service metastore\n\n# \u540e\u53f0\u542f\u52a8\nnohup bin/hive --service metastore >> logs/metastore.log 2>&1 &\n\nwjf@node0:/server/apache-hive-3.1.3-bin$ jps\n2341 Jps\n1686 NameNode\n1913 SecondaryNameNode\n1372 RunJar\n1773 DataNode\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u6709\u4e24\u79cd\u5ba2\u6237\u7aef\uff0c \u4e00\u79cd\u662f Hive shell\uff0c \u53ef\u76f4\u63a5\u5199 sql \uff0c \u901a\u8fc7 ",(0,a.jsx)(n.code,{children:"bin/hive"}),"  \u542f\u52a8\u3002\u53e6\u4e00\u79cd\u662f Hive ThriftServer \uff0c\u9700\u8981\u8fde\u63a5\u5916\u90e8\u5ba2\u6237\u7aef\uff0c ",(0,a.jsx)(n.code,{children:"bin/hive --service hiveserver2"})]}),"\n",(0,a.jsx)(n.p,{children:"\uff08\u542f\u52a8\u5ba2\u6237\u7aef\u4e4b\u524d\u5148\u628a hdfs \u548c yarn \u542f\u52a8\u8d77\u6765\uff09"}),"\n",(0,a.jsx)(n.p,{children:"\u53ef\u4ee5\u770b\u5230\u6709\u4e00\u4e2a default \u6570\u636e\u5e93"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ bin/hive\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/server/apache-hive-3.1.3-bin/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n...\nHive Session ID = d93a6567-47b3-43d8-b6da-5eb936f5c6d9\nhive> show databases;\nOK\ndefault\nTime taken: 0.031 seconds, Fetched: 1 row(s)\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u521b\u5efa\u8868\uff0c\u63d2\u5165\u6570\u636e\uff0c\u9700\u8981\u8ba1\u7b97\u7684 sql \u4f1a\u7ecf\u8fc7 mapReduce\uff0c\u7528\u65f6\u7279\u522b\u957f\u3002\u3002\u3002\u53ef\u4ee5\u5728 yarn \u7684\u9875\u9762\u67e5\u770b\u4efb\u52a1"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"hive> create table test(id int, name string, gender string);\nOK\nhive> insert into test(id, name, gender) values(3,'jim','M');\nQuery ID = wjf_20230525225053_71997c85-7263-459a-8a7c-25a95db71411\nTotal jobs = 3\nLaunching Job 1 out of 3\nNumber of reduce tasks determined at compile time: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nStarting Job = job_1685026202353_0001, Tracking URL = http://node0:8088/proxy/application_1685026202353_0001/\nKill Command = /server/hadoop-3.3.5/bin/mapred job  -kill job_1685026202353_0001\nHadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n2023-05-25 22:51:54,775 Stage-1 map = 0%,  reduce = 0%\n2023-05-25 22:52:11,383 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.4 sec\n2023-05-25 22:52:32,190 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.83 sec\nMapReduce Total cumulative CPU time: 5 seconds 830 msec\nEnded Job = job_1685026202353_0001\nStage-4 is selected by condition resolver.\nStage-3 is filtered out by condition resolver.\nStage-5 is filtered out by condition resolver.\nMoving data to directory hdfs://node0:8020/user/hive/warehouse/test/.hive-staging_hive_2023-05-25_22-50-53_595_7784313467016506868-1/-ext-10000\nLoading data to table default.test\nMapReduce Jobs Launched: \nStage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.83 sec   HDFS Read: 16341 HDFS Write: 273 SUCCESS\nTotal MapReduce CPU Time Spent: 5 seconds 830 msec\nOK\nTime taken: 102.321 seconds\nhive> select * from test;\nOK\n3\tjim\tM\nTime taken: 0.326 seconds, Fetched: 1 row(s)\nhive> select gender, count(*) from test group by gender;\nQuery ID = wjf_20230525225744_71573bcb-9912-4616-b40a-34da45252226\nTotal jobs = 1\nLaunching Job 1 out of 1\nNumber of reduce tasks not specified. Estimated from input data size: 1\nIn order to change the average load for a reducer (in bytes):\n  set hive.exec.reducers.bytes.per.reducer=<number>\nIn order to limit the maximum number of reducers:\n  set hive.exec.reducers.max=<number>\nIn order to set a constant number of reducers:\n  set mapreduce.job.reduces=<number>\nStarting Job = job_1685026202353_0002, Tracking URL = http://node0:8088/proxy/application_1685026202353_0002/\nKill Command = /server/hadoop-3.3.5/bin/mapred job  -kill job_1685026202353_0002\nHadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n2023-05-25 22:58:34,876 Stage-1 map = 0%,  reduce = 0%\n2023-05-25 22:58:46,462 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.16 sec\n2023-05-25 22:59:03,818 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.49 sec\nMapReduce Total cumulative CPU time: 5 seconds 490 msec\nEnded Job = job_1685026202353_0002\nMapReduce Jobs Launched: \nStage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.49 sec   HDFS Read: 12811 HDFS Write: 103 SUCCESS\nTotal MapReduce CPU Time Spent: 5 seconds 490 msec\nOK\nM\t1\nTime taken: 80.142 seconds, Fetched: 1 row(s)\n"})}),"\n",(0,a.jsxs)(n.p,{children:["default \u6570\u636e\u5e93\u4e2d\u7684 test \u8868\u5b58\u653e\u5728 ",(0,a.jsx)(n.code,{children:"/user/hive/warehouse/test/"})," \uff0c\u67e5\u770b\u6587\u4ef6\u53ef\u4ee5\u770b\u5230\u8868\u7684\u5185\u5bb9\uff08\u5217\u4e4b\u95f4\u6709\u4e0d\u53ef\u89c1\u7684\u5206\u9694\u7b26\uff09"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"wjf@node0:/server/apache-hive-3.1.3-bin/logs$ hdfs dfs -ls -r /user/hive/warehouse/test\nFound 1 items\n-rw-r--r--   3 wjf supergroup          8 2023-05-25 22:52 /user/hive/warehouse/test/000000_0\nwjf@node0:/server/apache-hive-3.1.3-bin/logs$ hdfs dfs -cat /user/hive/warehouse/test/*\n3jimM\n4MaryF\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"hiveserver2 \u662f Hive \u5185\u7f6e\u7684 ThriftServer \u670d\u52a1\uff0c\u63d0\u4f9b Thrift \u7aef\u53e3\u4f9b\u5176\u4ed6\u5ba2\u6237\u7aef\u8fde\u63a5\uff0c\u4f8b\u5982 Hive \u5185\u7f6e\u7684 beeline"}),"\n",(0,a.jsxs)(n.p,{children:["\u542f\u52a8 hiveserver2 \uff0cJPS \u4e2d\u540c\u6837\u540d\u79f0\u662f ",(0,a.jsx)(n.code,{children:"RunJar"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"nohup bin/hive --service hiveserver2 >> logs/hiveserver2.log 2>&1 &\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"bin/beeline"})," \u542f\u52a8 beeline \uff0c\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"!connect"})," \u547d\u4ee4\u8fde\u63a5\u6570\u636e\u5e93"]}),"\n",(0,a.jsx)(n.p,{children:"\u9700\u8981\u6dfb\u52a0\u4ee5\u4e0b\u914d\u7f6e\uff0c\u4e0d\u7136 beeline \u65e0\u6cd5\u8fde\u63a5"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# hive-site.xml\n<property>\n <name>hive.server2.enable.doAs</name>\n <value>true</value>\n</property>  \n\n\n# hadoop core-site.xml\n<property>\n  <name>hadoop.proxyuser.myusergroup.groups</name>\n<value>*</value>\n</property>\n\n<property>\n <name>hadoop.proxyuser.myusername.hosts</name>\n <value>*</value>\n</property>\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u542f\u52a8 beeline"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ bin/beeline \nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/server/apache-hive-3.1.3-bin/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/server/hadoop-3.3.5/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/server/apache-hive-3.1.3-bin/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/server/hadoop-3.3.5/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\nBeeline version 3.1.3 by Apache Hive\nbeeline> !connect jdbc:hive2://node0:10000 \nConnecting to jdbc:hive2://node0:10000\nEnter username for jdbc:hive2://node0:10000: wjf\nEnter password for jdbc:hive2://node0:10000: \nConnected to: Apache Hive (version 3.1.3)\nDriver: Hive JDBC (version 3.1.3)\nTransaction isolation: TRANSACTION_REPEATABLE_READ\n0: jdbc:hive2://node0:10000> select * from test;\nINFO  : Compiling command(queryId=wjf_20230529222057_b1e2de31-e06a-4447-9438-a7019fc98105): select * from test\nINFO  : Concurrency mode is disabled, not creating a lock manager\nINFO  : Semantic Analysis Completed (retrial = false)\nINFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:test.id, type:int, comment:null), FieldSchema(name:test.name, type:string, comment:null), FieldSchema(name:test.gender, type:string, comment:null)], properties:null)\nINFO  : Completed compiling command(queryId=wjf_20230529222057_b1e2de31-e06a-4447-9438-a7019fc98105); Time taken: 2.595 seconds\nINFO  : Concurrency mode is disabled, not creating a lock manager\nINFO  : Executing command(queryId=wjf_20230529222057_b1e2de31-e06a-4447-9438-a7019fc98105): select * from test\nINFO  : Completed executing command(queryId=wjf_20230529222057_b1e2de31-e06a-4447-9438-a7019fc98105); Time taken: 0.003 seconds\nINFO  : OK\nINFO  : Concurrency mode is disabled, not creating a lock manager\n+----------+------------+--------------+\n| test.id  | test.name  | test.gender  |\n+----------+------------+--------------+\n| 3        | jim        | M            |\n| 4        | Mary       | F            |\n| 1        | John       | M            |\n| 2        | sam        | M            |\n+----------+------------+--------------+\n4 rows selected (3.112 seconds)\n"})}),"\n",(0,a.jsx)(n.p,{children:"beeline \u4f7f\u7528\u8d77\u6765\u8f83\u539f\u751f\u547d\u4ee4\u884c\u5ba2\u6237\u7aef\u66f4\u7f8e\u89c2\u3002\u4e5f\u53ef\u4ee5\u4f7f\u7528\u56fe\u5f62\u5316\u7684 DataGrip \u548c DBeaver \u8fde\u63a5 Hive \uff0c\u4f7f\u7528\u4f53\u9a8c\u66f4\u597d"}),"\n",(0,a.jsx)(n.p,{children:"\u521b\u5efa\u6570\u636e\u5e93"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"0: jdbc:hive2://node0:10000> create database mydatabase1;\n\nNo rows affected (0.104 seconds)\n0: jdbc:hive2://node0:10000> show databases;\nI\n+----------------+\n| database_name  |\n+----------------+\n| default        |\n| mydatabase1    |\n+----------------+\n2 rows selected (0.079 seconds)\n0: jdbc:hive2://node0:10000> use mydatabase1;\nNo rows affected (0.075 seconds)\n0: jdbc:hive2://node0:10000> create table test(id int);\nNo rows affected (0.683 seconds)\n0: jdbc:hive2://node0:10000> show tables;\n+-----------+\n| tab_name  |\n+-----------+\n| test      |\n+-----------+\n1 row selected (0.111 seconds)\n0: jdbc:hive2://node0:10000> desc test;\n+-----------+------------+----------+\n| col_name  | data_type  | comment  |\n+-----------+------------+----------+\n| id        | int        |          |\n+-----------+------------+----------+\n1 row selected (0.097 seconds)\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u6570\u636e\u5e93\u64cd\u4f5c\u547d\u4ee4"}),"\n",(0,a.jsxs)(n.p,{children:["HIVE \u5e93\u5728 hdfs \u4e0a\u662f\u4e00\u4e2a\u540d\u79f0\u4ee5 ",(0,a.jsx)(n.code,{children:".db"})," \u7ed3\u5c3e\u7684\u6587\u4ef6\u5939"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# \u521b\u5efa\u6570\u636e\u5e93\uff0c\u9ed8\u8ba4\u8def\u5f84 hdfs://ip:port/user/hive/warehouse/databasename.db \ncreate database [if not exists] db_name [location '/path/to/database'];\n# \u5220\u9664\u6570\u636e\u5e93\uff0c\u5982\u679c\u5b58\u5728\u8868\u9700\u8981\u52a0\u4e0a cascade\ndrop database db_name [cascade];\n# \u6570\u636e\u5e93\u8be6\u7ec6\u4fe1\u606f\ndesc database db_name\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u521b\u5efa\u8868"}),"\n",(0,a.jsx)(n.p,{children:"hive \u5305\u62ec \u5185\u90e8\u8868\uff0c\u5916\u90e8\u8868\uff0c\u7b49\u3002\u5185\u90e8\u8868\u9ed8\u8ba4\u4f4d\u7f6e /user/hive/warehouse \uff0c\u9ed8\u8ba4\u521b\u5efa\u7684\u662f\u5185\u90e8\u8868\uff0cdesc \u663e\u793a managed_table \u3002\u5916\u90e8\u8868\u521b\u5efa\u9700\u8981\u52a0\u4e0a external \u5e76\u52a0\u4e0a location \uff08\u8def\u5f84\uff0c\u6587\u4ef6\u5939\u7ea7\u522b\uff09\uff0cdesc \u663e\u793a external_table\u3002\u5220\u9664\u5185\u90e8\u8868\u4f1a\u5220\u9664\u6570\u636e\u548c\u5143\u4fe1\u606f\uff0c\u662f hive \u7ba1\u7406\u7684\u8868\uff0c\u6301\u4e45\u4f7f\u7528\u3002\u5916\u90e8\u8868\u53ea\u4f1a\u5220\u9664\u5143\u6570\u636e\uff0c\u6570\u636e\u4f1a\u4fdd\u7559\uff0c\u7528\u4e8e\u4e34\u65f6\u94fe\u63a5\u5916\u90e8\u6570\u636e\uff0c\u53ef\u4ee5\u5148\u6709\u8868\u4e5f\u53ef\u4ee5\u5148\u6709\u6570\u636e"}),"\n",(0,a.jsxs)(n.p,{children:["\u521b\u5efa\u8868\u65f6\u53ef\u4ee5\u81ea\u5b9a\u4e49\u5217\u5206\u9694\u7b26\uff0c\u5916\u90e8\u8868\u901a\u5e38\u81ea\u5b9a\u4e49\u5206\u9694\u7b26\uff0c\u4e0e\u5916\u90e8\u6570\u636e\u4fdd\u6301\u4e00\u81f4\uff0c\u9ed8\u8ba4\u5206\u9694\u7b26 ",(0,a.jsx)(n.code,{children:"^A"})," \uff0c\u4e5f\u5c31\u662f 8 \u8fdb\u5236 ",(0,a.jsx)(n.code,{children:"\\001"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# \u521b\u5efa\u5185\u90e8\u8868\ncreate table tb_name (col_name col_type ...)\n# \u521b\u5efa\u5916\u90e8\u8868\ncraete external table tb_name (col_name col_type ...) row format delimited fields terminated by '\\t' location ...\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5bfc\u5165\u6570\u636e\u521b\u5efa\u4e00\u4e2a\u5916\u90e8\u8868"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ hdfs dfs -cat /my/table/mytable.txt\n1\tjeff\n2\tjohn\n3\tmary\n4\ttim\n> create external table mytable (id int, name string) row format delimited fields terminated by '\\t' location '/my/table';\n> select * from mytable;\n+-------------+---------------+\n| mytable.id  | mytable.name  |\n+-------------+---------------+\n| 1           | jeff          |\n| 2           | john          |\n| 3           | mary          |\n| 4           | tim           |\n+-------------+---------------+\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5185\u5916\u90e8\u8868\u8f6c\u6362"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"alter table tb_name set tblproperties('EXTERNAL'='TRUE' | 'FALSE')\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u52a0\u8f7d\u6570\u636e"}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 LOAD DATA \u547d\u4ee4\u52a0\u8f7d\uff0cLOCAL \u4ee3\u8868\u672c\u5730\u6570\u636e\uff0c\u4e0d\u5e26 ",(0,a.jsx)(n.code,{children:"LOCAL"})," \u8868\u793a HDFS \u8def\u5f84\uff0c ",(0,a.jsx)(n.code,{children:"OVERWRITE"})," \u8986\u76d6\u5df2\u7ecf\u5b58\u5728\u7684\u3002\u5982\u679c\u57fa\u4e8e hdfs \u52a0\u8f7d\u6570\u636e\uff0c\u6e90\u6587\u4ef6\u4f1a\u79fb\u52a8\u5230\u8868\u6240\u5728\u7684\u76ee\u5f55\uff0c\u6e90\u6587\u4ef6\u4f1a\u6d88\u5931\u3002\u4e5f\u53ef\u4ee5\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"insert select"})," \u547d\u4ee4\u5bfc\u5165\u6570\u636e\uff0c\u4f1a\u8d70 mapreduce"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tb_name\ninsert [into | overwrite] table tb1 select * from tb2\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u5bfc\u51fa\u6570\u636e\u547d\u4ee4\u7c7b\u4f3c\u3002\u5982\u679c\u4e0d\u5b9a\u4e49\u5206\u9694\u7b26\uff0c\u9ed8\u8ba4\u5c31\u662f ",(0,a.jsx)(n.code,{children:"\\001"})," \u3002\u5982\u679c\u4e0d\u52a0 local \u5219\u5bfc\u5165\u5230 hdfs"]}),"\n",(0,a.jsxs)(n.p,{children:["\u4e5f\u53ef\u4ee5\u4f7f\u7528 hive shell \u5bfc\u51fa \uff0c ",(0,a.jsx)(n.code,{children:"-e"})," \u8868\u793a\u6267\u884c sql \u8bed\u53e5\uff0c",(0,a.jsx)(n.code,{children:"-f"})," \u8868\u793a\u6267\u884c sql \u6587\u4ef6\uff0c\u7136\u540e\u91cd\u5b9a\u5411"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"insert overwrite [local] directory '/my/dir' [row format delimited fields terminated by '\\t'] select * from tb\n\nbin/hive -e \u201cselect * from db1.tb1;\" > /path\nbin/hive -f export.sql > /path\n"})}),"\n",(0,a.jsx)(n.p,{children:"Hive \u4e5f\u6709\u5206\u533a\u8868\u7684\u6982\u5ff5\uff0c\u7c7b\u4f3c\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u5206\u5e93\u5206\u8868\uff0c\u5f53\u6570\u636e\u91cf\u5927\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u4f7f\u7528\u5206\u533a\u8868\uff0c\u5206\u533a\u8868\u662f\u901a\u8fc7\u6587\u4ef6\u5939\u5b9e\u73b0\u7684\u3002\u67e5\u8be2\u6570\u636e\u7684\u65f6\u5019\u4f1a\u989d\u5916\u5e26\u4e0a\u5206\u533a\u5217\u3002\u5206\u533a\u53ef\u4ee5\u591a\u5c42\u7ea7\uff0c\u63d2\u5165\u7684\u7684\u65f6\u5019\u8981\u6307\u5b9a\u6bcf\u4e00\u5c42\u3002"}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"partition"})," \u521b\u5efa\u5206\u533a\u8868"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"create table tb_name(...) paartitioned by (\u5206\u533a\u5217 \u5217\u7c7b\u578b, ...) row format delimited fields terminated by '\\t'\nload data local inpath '/path.txt' into table mydb.mytable partition(mounth='202306')\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u63d2\u5165\u6570\u636e\uff0c\u6570\u636e\u4f1a\u5e26\u4e0a\u5206\u533a\u5217"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:">load data local inpath '/server/tmp/student.txt' into table mydb.student partition(month='202306');\n\n> select * from mydb.student;\n+-------------+----------------+----------------+\n| student.id  | student.score  | student.month  |\n+-------------+----------------+----------------+\n| jeff        | 99             | 202306         |\n| merry       | 100            | 202306         |\n| john        | 89             | 202306         |\n| jim         | 93             | 202306         |\n+-------------+----------------+----------------+\n"})}),"\n",(0,a.jsxs)(n.p,{children:["\u6570\u636e\u5b58\u653e\u5728 ",(0,a.jsx)(n.code,{children:"/user/hive/warehouse/mydb.db/student/month=202306/student.txt"})]}),"\n",(0,a.jsx)(n.p,{children:"\u540c\u6837\u7684\uff0c\u53ef\u4ee5\u521b\u5efa\u591a\u5206\u533a\u5217\uff0c\u63d2\u5165\u65f6\u9700\u8981\u6307\u5b9a\u6240\u6709\u5206\u533a"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"create table mydb.student2(id string, score int) partitioned by (year string, month string) row format delimited fields terminated by '\\t';\nload data local inpath '/server/tmp/student.txt' into table mydb.student2 partition(year='2023',month='06');\n# \u6570\u636e\u5b58\u653e\u5728 /user/hive/warehouse/mydb.db/student2/year=2023/month=06/student.txt\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5206\u6876\u8868"}),"\n",(0,a.jsx)(n.p,{children:"\u7c7b\u4f3c\u4e8e\u5206\u533a\u8868\uff0c\u4e0d\u540c\u4e8e\u5206\u533a\u8868\u5c06\u6587\u4ef6\u5b58\u653e\u5728\u4e0d\u540c\u6587\u4ef6\u5939\u4e2d\uff0c\u5206\u6876\u662f\u5c06\u8868\u62c6\u5206\u5230\u56fa\u5b9a\u6570\u91cf\u7684\u4e0d\u540c\u6587\u4ef6\u4e2d"}),"\n",(0,a.jsxs)(n.p,{children:["\u4f7f\u7528 ",(0,a.jsx)(n.code,{children:"clustered by(col) into n buckets"})," \u521b\u5efa\u5206\u6876\u8868"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# \u81ea\u52a8\u5339\u914d reduce task \u6570\u91cf\u4e0e\u6876\u6570\u91cf\u4e00\u81f4\nset hive.enforce.bucketing=true;\n\n# \u521b\u5efa\u5206\u6876\u8868\ncreate table student3(id string, score int) clustered by (id) into 3 buckets row format delimited fields terminated by '\\t';\n\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5206\u6876\u8868\u65e0\u6cd5\u901a\u8fc7 load data \u52a0\u8f7d\u6570\u636e\uff0c\u53ea\u80fd\u901a\u8fc7 insert select \u3002\u6bd4\u8f83\u597d\u7684\u65b9\u5f0f\u662f\u521b\u5efa\u4e34\u65f6\u8868\uff0c\u901a\u8fc7 load data \u52a0\u8f7d\u5230\u4e34\u65f6\u8868\uff0c\u518d\u901a\u8fc7 insert select \u52a0\u8f7d"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"# \u521b\u5efa\u4e34\u65f6\u8868\ncreate table student3_tmp(id string, score int) row format delimited fields terminated by '\\t';\n# \u4e34\u65f6\u8868\u52a0\u8f7d\u6570\u636e\nload data local inpath '/server/tmp/student.txt' into table mydb.student3_tmp;\n# \u63d2\u5165\u6570\u636e\uff08\u5c0f\u6570\u636e\u91cf\u7279\u522b\u6162\uff09\ninsert overwrite table mydb.student3 select * from mydb.student3_tmp cluster by(id);\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u8868\u88ab\u5206\u4e3a 3 \u5206\u5b58\u50a8\uff0c\u6570\u636e\u6309\u7167 hash \u5206\u5230\u4e0d\u540c\u6587\u4ef6"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"$ hdfs dfs -ls /user/hive/warehouse/mydb.db/student3\nFound 3 items\n-rw-r--r--   3 wjf supergroup         15 2023-06-07 22:52 /user/hive/warehouse/mydb.db/student3/000000_0\n-rw-r--r--   3 wjf supergroup         10 2023-06-07 22:52 /user/hive/warehouse/mydb.db/student3/000001_0\n-rw-r--r--   3 wjf supergroup         15 2023-06-07 22:52 /user/hive/warehouse/mydb.db/student3/000002_0\n"})}),"\n",(0,a.jsx)(n.p,{children:"\u5206\u6876\u8868\u53ef\u4ee5\u63d0\u5347\u6548\u7387\uff0c\u4f8b\u5982\u67e5\u8be2\uff0c\u901a\u8fc7 hash \u8ba1\u7b97\uff0c\u77e5\u9053\u503c\u5728\u54ea\u4e2a\u6876\u91cc\uff0c\u5c31\u53ef\u4ee5\u8fc7\u6ee4\u6389\u5f88\u591a\u65e0\u5173\u7684\u6876"})]})}function l(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>d});var o=r(6540);const a={},t=o.createContext(a);function s(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);